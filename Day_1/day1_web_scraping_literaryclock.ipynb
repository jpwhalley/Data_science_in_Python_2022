{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for Global Health - Data science in Python\n",
    "## Day 1: Collecting disparate data online by web scraping using Selenium and BeautifulSoup\n",
    "\n",
    "Ideally the data we wish to work on can be downloaded in an easy to use format. Otherwise when we want only a small subset of a very big dataset, or the data is being constantly updated, hopefully the owner will provide an application programming interface (API) to automate the collection of the relevant data. However quite often the data cannot be downloaded and there is no API, but the data is publicly available, just dispersed across a website. When it would be too tedious and time consuming to navigate page by page to collect the data manually; we can use Selenium Webdriver and Beautiful Soup to automate navigating across the website and collecting of the relevant data. In this code clinic, I will go through the best practices (and what not to do!) when web scraping; using Selenium Webdriver to navigate around a website and then using Beautiful Soup to extract the data from the HTML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: Why automate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 - get KIR haplotypes\n",
    "def get_hap():\n",
    "    \"\"\"Python file to get the KIR haplotypes:\n",
    "        KIR_barcode2haplotype.py\n",
    "\n",
    "        Python reference file for barcode to haplotype:\n",
    "        results/allelefreqdotnet_barcode2haplotype.p\n",
    "\n",
    "        Excel reference file for barcode to haplotype:\n",
    "        KIR_af_haplotypes_reference.csv\n",
    "\n",
    "        Results of the police men from Guinea Bissau:\n",
    "        db_police_final.csv\n",
    "    \"\"\"\n",
    "    # Open Webrowser\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from selenium import webdriver\n",
    "    from time import sleep\n",
    "    from random import randint\n",
    "    from natsort import natsorted\n",
    "    \n",
    "    ref = ['3DL1', '2DL1', '2DL3', '2DS4', '2DL2', '2DL5', '3DS1', '2DS1', '2DS2', '2DS3', '2DS5', '2DL4', '3DL2', '3DL3', '2DP1', '3DP1']\n",
    "    to_redo = ['1111011111111111', '1111110110111111', '1111110011011111', '1111000000011111', '1111110010111111']\n",
    "    \n",
    "    browser = webdriver.Firefox()\n",
    "\n",
    "    # Set constants\n",
    "    base_url = \"http://allelefrequencies.net/kir6001a.asp?kgen_pop_selection=&kgen_group=&kgen_id=&kgen_country=&kgen_pops_pattern=equal&kgen_pops=&kgen_dataset=&kgen_region=&kgen_ethnic=&kgen_study=&kgen_order=order_1&\"\n",
    "    \n",
    "    wrong = []\n",
    "    for barcode in set(to_redo):\n",
    "        end_url = ''\n",
    "        for i,j in zip(ref, barcode):\n",
    "            end_url += i + '=' + str(j) + '&'\n",
    "        end_url = end_url[:-1]\n",
    "        url = base_url + end_url\n",
    "        \n",
    "        browser.get(url)\n",
    "        html_source = browser.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "        for node in soup.findAll(attrs={'class': re.compile(r\"table01\")}):\n",
    "            if (node.td is None) or (node.td.contents[0] == '\\xa0'):\n",
    "                print('Missing')\n",
    "                Xx_count += 1\n",
    "                af_hap = 'Xx' + str(Xx_count)\n",
    "                break # Finds more than one table if the data is missing\n",
    "            elif 'AA' in node.td.contents[0]:\n",
    "                print('Got it')\n",
    "                af_hap = node.td.next.next + node.td.next.next.next.next.next.a.contents[0]\n",
    "            else:\n",
    "                print('Got it')\n",
    "                af_hap = node.td.contents[0].rstrip() + node.td.next.next.next.a.contents[0]\n",
    "        \n",
    "        print(barcode, af_hap)\n",
    "        # barcode2haplotype[barcode] = af_hap\n",
    "        sleep(5 + (randint(1,50) / 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got it\n",
      "1111110011011111 Bx5\n",
      "Got it\n",
      "1111110110111111 Bx9\n",
      "Got it\n",
      "1111000000011111 AA1\n",
      "Got it\n",
      "1111011111111111 Bx56\n",
      "Got it\n",
      "1111110010111111 Bx21\n"
     ]
    }
   ],
   "source": [
    "# Example collecting KIR haplotypes from allelefrequencies.net\n",
    "get_hap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Book                Author  \\\n",
      "0   The kiwi's egg : Charles Darwin and natural se...         David Quammen   \n",
      "1             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "2             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "3             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "4             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "5             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "6             Blueprint : how DNA makes us who we are         Robert Plomin   \n",
      "7   Human compatible : artificial intelligence and...        Stuart Russell   \n",
      "8   Fake law : the truth about justice in an age o...  The Secret Barrister   \n",
      "9   Fake law : the truth about justice in an age o...  The Secret Barrister   \n",
      "10  Fake law : the truth about justice in an age o...  The Secret Barrister   \n",
      "11  Fake law : the truth about justice in an age o...  The Secret Barrister   \n",
      "12  Fake law : the truth about justice in an age o...  The Secret Barrister   \n",
      "13                                         Somersault          Kenzaburo Oe   \n",
      "\n",
      "               Library                  Status Classification  \n",
      "0   Oxfordshire County           Check shelves       B.DARWIN  \n",
      "1              Banbury  Not available for loan          155.7  \n",
      "2               Didcot           Check shelves          155.7  \n",
      "3   Oxfordshire County           Check shelves          155.7  \n",
      "4            Carterton           Check shelves          155.7  \n",
      "5           Summertown           Check shelves          155.7  \n",
      "6          Wallingford  Not available for loan          155.7  \n",
      "7   Oxfordshire County  Not available for loan          006.3  \n",
      "8               Benson           Check shelves        364.941  \n",
      "9            Carterton           Check shelves        364.941  \n",
      "10              Didcot  Not available for loan        364.941  \n",
      "11              Henley           Check shelves        364.941  \n",
      "12  Oxfordshire County  Not available for loan        364.941  \n",
      "13  Oxfordshire County           Check shelves        Fiction  \n"
     ]
    }
   ],
   "source": [
    "# Example 2 - Get Library books\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://libcat.oxfordshire.gov.uk/web/arena/results?p_p_id=crDetailWicket_WAR_arenaportlet&p_p_lifecycle=1&p_p_state=normal&p_r_p_arena_urn%3Aarena_search_item_id=\"\n",
    "\n",
    "# Name /Author :[arena_search_item_id]\n",
    "books = {\n",
    "\"The kiwi's egg : Charles Darwin and natural selection / David Quammen\" :['0297845691&p'],\n",
    "'Blueprint : how DNA makes us who we are / Robert Plomin' :['0241282071&p', '0141984260&p'],\n",
    "'Human compatible : artificial intelligence and the problem of control / Stuart Russell' :['0241335205&p'],\n",
    "'Fake law : the truth about justice in an age of lies / The Secret Barrister' :['1529009944&p'],\n",
    "'Somersault / Kenzaburo Oe' :['1843540800&p']}\n",
    "\n",
    "\n",
    "browser = webdriver.Firefox()\n",
    "results = {}\n",
    "count = 0\n",
    "for book in books:\n",
    "    for version in books[book]:\n",
    "        browser.get(url + version)\n",
    "        sleep(6.25 + (randint(1,50) / 25))\n",
    "        html_source = browser.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html_source)\n",
    "        \n",
    "        for foo in soup.find_all('div', attrs={'class': 'arena-holding-container clearfix'}):\n",
    "            if foo.text != 'Oxfordshire':\n",
    "                results[count] = {}\n",
    "                results[count]['Book'] = book.split(' / ')[0]\n",
    "                results[count]['Author'] = book.split(' / ')[1]\n",
    "                results[count]['Library'] = foo.text.replace(' Library', '').strip()\n",
    "                results[count]['Status'] = foo.find_next('div', attrs={'class': 'arena-availability-right'}).text.replace('\\n', '')\n",
    "                if foo.find_previous('div', attrs={'class': 'arena-detail-class'}) != None:\n",
    "                    results[count]['Classification'] = foo.find_previous('div', attrs={'class': 'arena-detail-class'}).text.split(': ')[1].replace(' ', '')\n",
    "                else:\n",
    "                    results[count]['Classification'] = 'Not known'\n",
    "                count += 1\n",
    "        \n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0: Load the packages and open a remote controlled browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from selenium import webdriver\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire up Selenium webdriver with the website we want to scrape\n",
    "browser = webdriver.Firefox() # If you use a different browser, replace Firefox with this\n",
    "base_url = \"https://www.literaryclock.com/\"\n",
    "browser.get(base_url)\n",
    "\n",
    "# # Alternatively, use requests\n",
    "# requests.get(base_url, timeout=1) # Hopefully get Response [200], not [404]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Navigating around using selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1: Using link text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"7f69073d-8066-4a67-91cc-056bd405c449\", element=\"af6624a6-011f-45c2-8fea-8a3a64fc752c\")>\n"
     ]
    }
   ],
   "source": [
    "# Start navigating around\n",
    "element = browser.find_element_by_link_text(\"Posts\")\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2: How to submit text, and limitations of being a robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to text, play around with inputing text\n",
    "browser.find_element_by_link_text(\"Contact\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"7f69073d-8066-4a67-91cc-056bd405c449\", element=\"997a0684-0d65-4496-8e37-53c740f143b6\")>\n"
     ]
    }
   ],
   "source": [
    "# Need to find the boxes to input text\n",
    "element = browser.find_element_by_css_selector('input[id=\"name\"]')\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.send_keys('Justin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly can you put text in the subject line\n",
    "browser.find_element_by_css_selector('input[id=\"subject\"]').send_keys('Hello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly different challenge in inputing data into the message box\n",
    "# Message is not an 'input', it is a textarea\n",
    "browser.find_element_by_css_selector('textarea[id=\"message\"]').send_keys('How are you doing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we automatically pretend not to be a robot, probably not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how do we click on the send button\n",
    "browser.find_element_by_css_selector('input[id=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Webscraping time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Can we get a the literary works, their authors and their date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to Posts\n",
    "browser.find_element_by_link_text(\"Posts\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: Element <a href=\"/posts/Lt5_Library\"> could not be scrolled into view\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/cdy3yr0n4n7f0p_yspl8smvm0000gn/T/ipykernel_2068/685020723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# And now The Literary Clock Library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Literary Clock Library\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mclick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mElementNotInteractableException\u001b[0m: Message: Element <a href=\"/posts/Lt5_Library\"> could not be scrolled into view\n"
     ]
    }
   ],
   "source": [
    "# And now The Literary Clock Library\n",
    "browser.find_element_by_link_text(\"The Literary Clock Library\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.firefox.webelement.FirefoxWebElement (session=\"7f69073d-8066-4a67-91cc-056bd405c449\", element=\"c8aa6ead-1afc-46d2-972d-a2f2601ad8eb\")>\n"
     ]
    }
   ],
   "source": [
    "# Use javascript to click on the element instead\n",
    "element = browser.find_element_by_link_text(\"The Literary Clock Library\")\n",
    "print(element)\n",
    "browser.execute_script(\"arguments[0].click();\", element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now to the 1500s\n",
    "browser.find_element_by_link_text(\"1500s\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we grab the plays first performed in the 1500s\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "# # Alternative with requests\n",
    "# html = requests.get(base_url+'library/1500', timeout=1)\n",
    "# soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<li><a href=\"/\">Home</a></li>\n"
     ]
    }
   ],
   "source": [
    "# Looking at the 'li' tag\n",
    "print(soup.li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li><a href=\"/\">Home</a></li>, <li><a href=\"/posts/\">Posts</a></li>, <li><a href=\"/contact\">Contact</a></li>, <li>1591: King Richard III by William Shakespeare</li>, <li>1599: As You Like It by William Shakespeare</li>]\n"
     ]
    }
   ],
   "source": [
    "# OK, get all the 'li' tags\n",
    "print(soup.findAll('li'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/\">Home</a>\n",
      "<a href=\"/posts/\">Posts</a>\n",
      "<a href=\"/contact\">Contact</a>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Look to see if it is a link or not\n",
    "for i in soup.findAll('li'):\n",
    "    print(i.a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/posts/\n",
      "/contact\n"
     ]
    }
   ],
   "source": [
    "# So we can filter out by link (and we can also look at the link)\n",
    "for i in soup.findAll('li'):\n",
    "    if i.a != None:\n",
    "        print(i.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = {}\n",
    "counter = 0\n",
    "for i in soup.findAll('li'):\n",
    "    if i.a == None:\n",
    "        books[counter] = {}\n",
    "        \n",
    "        book = i.string\n",
    "        \n",
    "        books[counter]['Year'] = int(book[:4])\n",
    "        \n",
    "        temp = book[6:].split(' by ')\n",
    "        \n",
    "        books[counter]['Title'] = temp[0]\n",
    "        books[counter]['Author'] = temp[1]\n",
    "        \n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year             Title               Author\n",
      "0  1591  King Richard III  William Shakespeare\n",
      "1  1599    As You Like It  William Shakespeare\n"
     ]
    }
   ],
   "source": [
    "# Can now look at this in a dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(books).T\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year                                   Title               Author\n",
      "0  1591                        King Richard III  William Shakespeare\n",
      "1  1599                          As You Like It  William Shakespeare\n",
      "2  1603                                  Hamlet  William Shakespeare\n",
      "3  1623                                 Macbeth  William Shakespeare\n",
      "4  1669  The Diary of Samuel Pepys: A Selection         Samuel Pepys\n"
     ]
    }
   ],
   "source": [
    "# OK, lets add the 1600s\n",
    "browser.find_element_by_partial_link_text(\"Next\").click() # Nice alternative to find_element_by_link_text\n",
    "\n",
    "# Now put all of the books from this page into the \"books\" dictionary\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "# # Alternative with requests\n",
    "# html = requests.get(base_url+'library/1600', timeout=1)\n",
    "# soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "for i in soup.findAll('li'):\n",
    "    if i.a == None:\n",
    "        books[counter] = {}\n",
    "        \n",
    "        book = i.string\n",
    "        \n",
    "        books[counter]['Year'] = int(book[:4])\n",
    "        \n",
    "        temp = book[6:].split(' by ')\n",
    "        \n",
    "        books[counter]['Title'] = temp[0]\n",
    "        books[counter]['Author'] = temp[1]\n",
    "        \n",
    "        counter +=1\n",
    "        \n",
    "df = pd.DataFrame(books).T\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Automatically get all the literary works, their authors and their date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/38/cdy3yr0n4n7f0p_yspl8smvm0000gn/T/ipykernel_2068/4161866651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# OK let's go back to the 1500s and try get them all\n",
    "from time import sleep\n",
    "browser.find_element_by_partial_link_text(\"Prev\").click()\n",
    "\n",
    "carry_on = True\n",
    "books = {}\n",
    "counter = 0\n",
    "while carry_on:\n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "    for i in soup.findAll('li'):\n",
    "        if i.a == None:\n",
    "            books[counter] = {}\n",
    "        \n",
    "            book = i.string\n",
    "            # print(book)\n",
    "        \n",
    "            books[counter]['Year'] = int(book[:4])\n",
    "        \n",
    "            temp = book[6:].split(' by ')\n",
    "        \n",
    "            books[counter]['Title'] = temp[0]\n",
    "            books[counter]['Author'] = temp[1]\n",
    "        \n",
    "            counter +=1\n",
    "            \n",
    "    try:\n",
    "        browser.find_element_by_partial_link_text(\"Next\").click()\n",
    "        sleep(2)\n",
    "    except:\n",
    "        carry_on=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year                                              Title  \\\n",
      "0  1591                                   King Richard III   \n",
      "1  1599                                     As You Like It   \n",
      "2  1603                                             Hamlet   \n",
      "3  1623                                            Macbeth   \n",
      "4  1669             The Diary of Samuel Pepys: A Selection   \n",
      "5  1759  The Life and Opinions of Tristram Shandy, Gent...   \n",
      "6  1790                               Mutiny on the Bounty   \n",
      "7  1798                    The Rime of the Ancient Mariner   \n",
      "8  1800                                             o 1850   \n",
      "\n",
      "                    Author  \n",
      "0      William Shakespeare  \n",
      "1      William Shakespeare  \n",
      "2      William Shakespeare  \n",
      "3      William Shakespeare  \n",
      "4             Samuel Pepys  \n",
      "5          Laurence Sterne  \n",
      "6            William Bligh  \n",
      "7  Samuel Taylor Coleridge  \n",
      "8                      NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(books).T\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, lets check how best to collect the data\n",
    "# Can do it in two parts - first up 1500s, 1600s and 1700s\n",
    "\n",
    "books = {}\n",
    "counter = 0\n",
    "for century in ['/1500', '/1600', '/1700']:\n",
    "    browser.get(base_url + 'library' + century)\n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "#     # Alternative with requests\n",
    "#     html = requests.get(base_url + 'library' + century, timeout=1)\n",
    "#     soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "    for i in soup.findAll('li'):\n",
    "        if i.a == None:\n",
    "            books[counter] = {}\n",
    "\n",
    "            book = i.string\n",
    "            # print(book)\n",
    "\n",
    "            books[counter]['Year'] = int(book[:4])\n",
    "\n",
    "            temp = book[6:].split(' by ')\n",
    "\n",
    "            books[counter]['Title'] = temp[0]\n",
    "            books[counter]['Author'] = temp[1]\n",
    "\n",
    "            counter +=1\n",
    "    \n",
    "    sleep(2)\n",
    "\n",
    "df = pd.DataFrame(books).T\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the 1800s, 1900s and 2000s\n",
    "for century in ['/1800', '/1900', '/2000']:\n",
    "    browser.get(base_url + 'library' + century)\n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "#     # Alternative with requests\n",
    "#     html = requests.get(base_url + 'library' + century, timeout=1)\n",
    "#     soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "    to_do = []\n",
    "    for i in soup.findAll('a'):\n",
    "        if '/library' + century in i['href']:\n",
    "            to_do.append(i['href'])\n",
    "    \n",
    "    for period in to_do:\n",
    "        browser.get(base_url + period)\n",
    "        html_source = browser.page_source\n",
    "        soup = BeautifulSoup(html_source, 'html.parser')\n",
    "        \n",
    "#         # Alternative with requests\n",
    "#         html = requests.get(base_url + period, timeout=1)\n",
    "#         soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        \n",
    "        for i in soup.findAll('li'):\n",
    "            if i.a == None:\n",
    "                books[counter] = {}\n",
    "\n",
    "                book = i.string\n",
    "                # print(book)\n",
    "\n",
    "                books[counter]['Year'] = int(book[:4])\n",
    "\n",
    "                temp = book[6:].split(' by ')\n",
    "\n",
    "                books[counter]['Title'] = temp[0]\n",
    "                books[counter]['Author'] = temp[1]\n",
    "\n",
    "                counter +=1\n",
    "        \n",
    "        sleep(2)\n",
    "\n",
    "df = pd.DataFrame(books).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Year'}>]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look to quickly plot the distribution of years\n",
    "df['Year'] = df['Year'].astype('int')\n",
    "df.hist(column='Year', bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1591</td>\n",
       "      <td>King Richard III</td>\n",
       "      <td>William Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1599</td>\n",
       "      <td>As You Like It</td>\n",
       "      <td>William Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1603</td>\n",
       "      <td>Hamlet</td>\n",
       "      <td>William Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1623</td>\n",
       "      <td>Macbeth</td>\n",
       "      <td>William Shakespeare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1669</td>\n",
       "      <td>The Diary of Samuel Pepys: A Selection</td>\n",
       "      <td>Samuel Pepys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>2016</td>\n",
       "      <td>Rampage</td>\n",
       "      <td>John Sandford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>2016</td>\n",
       "      <td>My Name Is Not Jacob Ramsay</td>\n",
       "      <td>Ben Trebilcook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>2016</td>\n",
       "      <td>The Screaming: Dead City</td>\n",
       "      <td>Matthew Warwick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2016</td>\n",
       "      <td>For Richer, For Poorer</td>\n",
       "      <td>Kerry Wilkinson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2017</td>\n",
       "      <td>Resurrection</td>\n",
       "      <td>Derek Landy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year                                   Title               Author\n",
       "0     1591                        King Richard III  William Shakespeare\n",
       "1     1599                          As You Like It  William Shakespeare\n",
       "2     1603                                  Hamlet  William Shakespeare\n",
       "3     1623                                 Macbeth  William Shakespeare\n",
       "4     1669  The Diary of Samuel Pepys: A Selection         Samuel Pepys\n",
       "...    ...                                     ...                  ...\n",
       "1308  2016                                 Rampage        John Sandford\n",
       "1309  2016             My Name Is Not Jacob Ramsay       Ben Trebilcook\n",
       "1310  2016                The Screaming: Dead City      Matthew Warwick\n",
       "1311  2016                  For Richer, For Poorer      Kerry Wilkinson\n",
       "1312  2017                            Resurrection          Derek Landy\n",
       "\n",
       "[1313 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/library/2000/2000',\n",
       " '/library/2000/2001',\n",
       " '/library/2000/2002',\n",
       " '/library/2000/2003',\n",
       " '/library/2000/2004',\n",
       " '/library/2000/2005',\n",
       " '/library/2000/2006',\n",
       " '/library/2000/2007',\n",
       " '/library/2000/2008',\n",
       " '/library/2000/2009',\n",
       " '/library/2000/2010',\n",
       " '/library/2000/2011',\n",
       " '/library/2000/2012',\n",
       " '/library/2000/2013',\n",
       " '/library/2000/2014',\n",
       " '/library/2000/2015',\n",
       " '/library/2000/2016',\n",
       " '/library/2000/2017']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
